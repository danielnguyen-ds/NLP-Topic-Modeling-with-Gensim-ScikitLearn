{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP-Topic-Modeling.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1wTFtSK3mmWoWJZUqXBX92CCg4rN6HIyW","authorship_tag":"ABX9TyM0abtUg+ttUELjcPgOXTvm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"P-PgUd68MF0o"},"source":["# NLP-Topic-Modeling\n","\n","Welcome to a new NLP project!\n","\n","In this project, we are going to cover topic modeling, or the unsupervised discovery of topics present in a corpus of text. There are many different algorithms available to do this, and we will cover four of them: \n","- Latent Dirichlet Allocation (LDA) topic modeling with sklearn\n","- LDA topic modeling with gensim\n","- NMF topic modeling\n","- K-means with Bidirectional Encoder Representations from Transformers (BERT) embeddings\n","- Gibbs Sampling Dirichlet Multinomial Mixture (GSDMM) for topic modeling of short texts."]},{"cell_type":"markdown","metadata":{"id":"LSvtz2vFMkcQ"},"source":["## Table of Contents\n","- [1 - Set up the working directory & Import packages ](#1)\n","- [2 - Load the dataset](#2)\n","- [3 - Preprocess the dataset](#3)\n","    - [Reshape the training and test data sets](#pre-1)\n","    - [Normalize the training and test data sets](#pre-2)\n","- [4 - Build the model](#4)\n","    - [4.1 - Define the model structure](#4-1)\n","    - [4.2 - Train the top layer](#4-2)\n","    - [4.3 - Do a round of fine-tuning of the entire model](#4-3)\n"]},{"cell_type":"markdown","metadata":{"id":"Z6ugWydrMpD0"},"source":["<a name='1'></a>\n","## 1 - Set up the working directory & Import packages ##"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XkZJryCHp5s","executionInfo":{"status":"ok","timestamp":1631938590531,"user_tz":300,"elapsed":3744,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"7b40f7cb-875c-4b18-d14c-d371c38e80f1"},"source":["# Get the running time of each cell \n","#  (similar to the ExecuteTime extension for Jupyter Notebook\n","!pip install ipython-autotime\n","%load_ext autotime"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","time: 191 Âµs (started: 2021-09-18 04:16:30 +00:00)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvtsXionMj-k","executionInfo":{"status":"ok","timestamp":1631934938242,"user_tz":300,"elapsed":243,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"ffd836f1-1ee3-44b4-ee38-2dfe347d0e2b"},"source":["# Move to the working directory on Google Drive as using Google Colab\n","import os\n","if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","  PROJECT_ROOT =\"/content/drive/MyDrive/GitHub/NLP-Topic-Modeling\"\n","else:\n","  PROJECT_ROOT =\".\"\n","os.chdir(PROJECT_ROOT)\n","!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab\n","/content/drive/MyDrive/GitHub/NLP-Topic-Modeling\n"]}]},{"cell_type":"code","metadata":{"id":"hAvtLJFPL_EG","executionInfo":{"status":"ok","timestamp":1631934942559,"user_tz":300,"elapsed":948,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}}},"source":["import re\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation as LDA\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdIkd-p_VorX","executionInfo":{"status":"ok","timestamp":1631934944787,"user_tz":300,"elapsed":102,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}}},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","sns.set_context('talk')\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","params = {'legend.fontsize': 11,\n","          'figure.figsize': (10, 5),\n","          'axes.labelsize': 11,\n","          'axes.titlesize':11,\n","          'xtick.labelsize':11,\n","          'ytick.labelsize':11}\n","plt.rcParams.update(params)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDSvTjtgNHPM"},"source":["<a name='2'></a>\n","## 2 - Load the dataset ##\n"]},{"cell_type":"markdown","metadata":{"id":"iU3IocnR6txU"},"source":["### Get the stopwords"]},{"cell_type":"code","metadata":{"id":"90m2hJw3M_fj","executionInfo":{"status":"ok","timestamp":1631934974103,"user_tz":300,"elapsed":244,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}}},"source":["import csv\n","from nltk.stem.snowball import SnowballStemmer\n","\n","\n","def read_in_csv(csv_file):\n","    with open(csv_file, 'r', encoding='utf-8') as fp:\n","        reader = csv.reader(fp, delimiter=',', quotechar='\"')\n","        data_read = [row for row in reader]\n","    return data_read\n","\n","\n","def get_stopwords(path):\n","    stemmer = SnowballStemmer('english')\n","    stopwords = read_in_csv(path)\n","    stopwords = [word[0] for word in stopwords]\n","    stemmed_stopwords = [stemmer.stem(word) for word in stopwords]\n","    stopwords = stopwords + stemmed_stopwords\n","    return stopwords\n","\n","stopwords_file_path = \"datasets/stopwords.csv\"\n","stopwords = get_stopwords(stopwords_file_path)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CH_H7rhyIIMR","executionInfo":{"status":"ok","timestamp":1631938712574,"user_tz":300,"elapsed":95,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"6cb1123e-9fc3-4681-aea8-178ddc6afebf"},"source":["stopwords "],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"'m\",\n"," \"'re\",\n"," \"'s\",\n"," \"'ve\",\n"," 'a',\n"," 'able',\n"," 'about',\n"," 'above',\n"," 'accordance',\n"," 'according',\n"," 'accordingly',\n"," 'across',\n"," 'actually',\n"," 'after',\n"," 'afterward',\n"," 'afterwards',\n"," 'again',\n"," 'against',\n"," 'ago',\n"," 'ah',\n"," 'all',\n"," 'along',\n"," 'already',\n"," 'also',\n"," 'although',\n"," 'always',\n"," 'am',\n"," 'among',\n"," 'amongst',\n"," 'an',\n"," 'and',\n"," 'another',\n"," 'any',\n"," 'anybody',\n"," 'anyhow',\n"," 'anymore',\n"," 'anyone',\n"," 'anything',\n"," 'anyway',\n"," 'anyways',\n"," 'anywhere',\n"," 'are',\n"," 'aren',\n"," \"aren'\",\n"," 'arent',\n"," 'around',\n"," 'as',\n"," 'aside',\n"," 'at',\n"," 'away',\n"," 'be',\n"," 'because',\n"," 'been',\n"," 'before',\n"," 'beforehand',\n"," 'behind',\n"," 'being',\n"," 'below',\n"," 'beside',\n"," 'besides',\n"," 'between',\n"," 'beyond',\n"," 'both',\n"," 'but',\n"," 'by',\n"," 'ca',\n"," 'can',\n"," \"can'\",\n"," \"can't\",\n"," 'cannot',\n"," 'cause',\n"," 'co',\n"," 'com',\n"," 'could',\n"," 'couldn',\n"," \"couldn'\",\n"," 'couldnt',\n"," 'day',\n"," 'days',\n"," 'despite',\n"," 'did',\n"," 'didn',\n"," \"didn'\",\n"," \"didn't\",\n"," 'do',\n"," 'does',\n"," 'doesn',\n"," \"doesn'\",\n"," \"doesn't\",\n"," 'doing',\n"," 'don',\n"," \"don't\",\n"," 'done',\n"," 'dont',\n"," 'down',\n"," 'downwards',\n"," 'during',\n"," 'each',\n"," 'ed',\n"," 'edu',\n"," 'eg',\n"," 'either',\n"," 'else',\n"," 'elsewhere',\n"," 'enough',\n"," 'et',\n"," 'et-al',\n"," 'etc',\n"," 'even',\n"," 'ever',\n"," 'every',\n"," 'everybody',\n"," 'everyone',\n"," 'everything',\n"," 'everywhere',\n"," 'except',\n"," 'ff',\n"," 'for',\n"," 'from',\n"," 'further',\n"," 'furthermore',\n"," 'go',\n"," 'goes',\n"," 'going',\n"," 'gone',\n"," 'got',\n"," 'gotten',\n"," 'had',\n"," 'has',\n"," \"hasn't\",\n"," 'have',\n"," 'haven',\n"," \"haven'\",\n"," \"haven't\",\n"," 'having',\n"," 'he',\n"," 'hed',\n"," 'hence',\n"," 'her',\n"," 'here',\n"," 'hereafter',\n"," 'hereby',\n"," 'herein',\n"," 'heres',\n"," 'hereupon',\n"," 'hers',\n"," 'herself',\n"," 'hes',\n"," 'hi',\n"," 'him',\n"," 'himself',\n"," 'his',\n"," 'hither',\n"," 'how',\n"," 'howbeit',\n"," 'however',\n"," 'i',\n"," \"i'll\",\n"," \"i've\",\n"," 'id',\n"," 'ie',\n"," 'if',\n"," 'im',\n"," 'in',\n"," 'inc',\n"," 'instead',\n"," 'into',\n"," 'is',\n"," 'isn',\n"," \"isn'\",\n"," \"isn't\",\n"," 'it',\n"," \"it'll\",\n"," 'itd',\n"," 'its',\n"," 'itself',\n"," 'just',\n"," 'kg',\n"," 'km',\n"," 'largely',\n"," 'lately',\n"," 'later',\n"," 'latter',\n"," 'latterly',\n"," 'least',\n"," 'less',\n"," 'lest',\n"," 'let',\n"," 'lets',\n"," 'like',\n"," 'likely',\n"," 'literally',\n"," 'little',\n"," 'll',\n"," 'lot',\n"," 'lots',\n"," 'ltd',\n"," 'made',\n"," 'mainly',\n"," 'many',\n"," 'matter',\n"," 'may',\n"," 'maybe',\n"," 'me',\n"," 'mean',\n"," 'means',\n"," 'meantime',\n"," 'meanwhile',\n"," 'merely',\n"," 'mg',\n"," 'might',\n"," 'ml',\n"," 'more',\n"," 'moreover',\n"," 'most',\n"," 'mostly',\n"," 'mr',\n"," 'mrs',\n"," 'much',\n"," 'must',\n"," 'my',\n"," 'myself',\n"," \"n't\",\n"," 'na',\n"," 'namely',\n"," 'nay',\n"," 'nd',\n"," 'near',\n"," 'neither',\n"," 'never',\n"," 'nevertheless',\n"," 'no',\n"," 'nobody',\n"," 'non',\n"," 'none',\n"," 'nonetheless',\n"," 'noone',\n"," 'nor',\n"," 'nos',\n"," 'not',\n"," 'nothing',\n"," 'now',\n"," 'nowhere',\n"," 'obviously',\n"," 'of',\n"," 'off',\n"," 'often',\n"," 'oh',\n"," 'ok',\n"," 'okay',\n"," 'on',\n"," 'once',\n"," 'one',\n"," 'ones',\n"," 'only',\n"," 'onto',\n"," 'or',\n"," 'ord',\n"," 'other',\n"," 'others',\n"," 'otherwise',\n"," 'ought',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'out',\n"," 'outside',\n"," 'over',\n"," 'overall',\n"," 'particularly',\n"," 'past',\n"," 'per',\n"," 'please',\n"," 'plus',\n"," 'pp',\n"," 'present',\n"," 'put',\n"," 'que',\n"," 'quite',\n"," 'qv',\n"," 'rather',\n"," 'rd',\n"," 're',\n"," 'really',\n"," 'ref',\n"," 'refs',\n"," 'regarding',\n"," 'regardless',\n"," 'regards',\n"," 'right',\n"," 's',\n"," 'said',\n"," 'same',\n"," 'saw',\n"," 'sec',\n"," 'second',\n"," 'seconds',\n"," 'see',\n"," 'seen',\n"," 'self',\n"," 'selves',\n"," 'seriously',\n"," 'several',\n"," 'shall',\n"," 'she',\n"," \"she'll\",\n"," 'shed',\n"," 'shes',\n"," 'should',\n"," \"shouldn't\",\n"," 'since',\n"," 'slightly',\n"," 'so',\n"," 'some',\n"," 'somebody',\n"," 'somehow',\n"," 'someone',\n"," 'somethan',\n"," 'something',\n"," 'sometime',\n"," 'sometimes',\n"," 'somewhat',\n"," 'somewhere',\n"," 'still',\n"," 'stuff',\n"," 'sub',\n"," 'such',\n"," 'sup',\n"," 'super',\n"," 'sure',\n"," 't',\n"," 'th',\n"," 'than',\n"," 'thank',\n"," 'thanks',\n"," 'thanx',\n"," 'that',\n"," \"that'll\",\n"," \"that've\",\n"," 'thats',\n"," 'the',\n"," 'their',\n"," 'theirs',\n"," 'them',\n"," 'themselves',\n"," 'then',\n"," 'thence',\n"," 'there',\n"," \"there'll\",\n"," \"there've\",\n"," 'thereafter',\n"," 'thereby',\n"," 'thered',\n"," 'therefore',\n"," 'therein',\n"," 'thereof',\n"," 'theres',\n"," 'thereto',\n"," 'thereupon',\n"," 'these',\n"," 'they',\n"," \"they'll\",\n"," \"they've\",\n"," 'theyd',\n"," 'theyre',\n"," 'thing',\n"," 'things',\n"," 'this',\n"," 'those',\n"," 'thou',\n"," 'though',\n"," 'though',\n"," 'thousand',\n"," 'through',\n"," 'throughout',\n"," 'thru',\n"," 'thus',\n"," 'til',\n"," 'till',\n"," 'to',\n"," 'too',\n"," 'totally',\n"," 'toward',\n"," 'towards',\n"," 'ts',\n"," 'twice',\n"," 'two',\n"," 'un',\n"," 'under',\n"," 'unless',\n"," 'unlike',\n"," 'unlikely',\n"," 'until',\n"," 'unto',\n"," 'up',\n"," 'upon',\n"," 'ups',\n"," 'us',\n"," 'usually',\n"," 've',\n"," 'veri',\n"," 'very',\n"," 'via',\n"," 'viz',\n"," 'vol',\n"," 'vols',\n"," 'vs',\n"," 'want',\n"," 'wants',\n"," 'was',\n"," 'wasn',\n"," \"wasn'\",\n"," 'wasnt',\n"," 'way',\n"," 'we',\n"," \"we'll\",\n"," \"we've\",\n"," 'wed',\n"," 'well',\n"," 'went',\n"," 'were',\n"," 'werent',\n"," 'what',\n"," \"what'll\",\n"," 'whatever',\n"," 'whats',\n"," 'when',\n"," 'whence',\n"," 'whenever',\n"," 'where',\n"," 'whereafter',\n"," 'whereas',\n"," 'whereby',\n"," 'wherein',\n"," 'wheres',\n"," 'whereupon',\n"," 'wherever',\n"," 'whether',\n"," 'which',\n"," 'while',\n"," 'whim',\n"," 'whither',\n"," 'who',\n"," \"who'll\",\n"," 'whod',\n"," 'whoever',\n"," 'whom',\n"," 'whomever',\n"," 'whos',\n"," 'whose',\n"," 'why',\n"," 'will',\n"," 'willing',\n"," 'with',\n"," 'within',\n"," 'without',\n"," 'wont',\n"," 'worse',\n"," 'worst',\n"," 'would',\n"," 'wouldn',\n"," \"wouldn'\",\n"," 'wouldnt',\n"," 'wow',\n"," 'www',\n"," 'yes',\n"," 'yet',\n"," 'you',\n"," \"you'll\",\n"," \"you've\",\n"," 'youd',\n"," 'your',\n"," 'youre',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," \"'m\",\n"," 're',\n"," \"'s\",\n"," 've',\n"," 'a',\n"," 'abl',\n"," 'about',\n"," 'abov',\n"," 'accord',\n"," 'accord',\n"," 'accord',\n"," 'across',\n"," 'actual',\n"," 'after',\n"," 'afterward',\n"," 'afterward',\n"," 'again',\n"," 'against',\n"," 'ago',\n"," 'ah',\n"," 'all',\n"," 'along',\n"," 'alreadi',\n"," 'also',\n"," 'although',\n"," 'alway',\n"," 'am',\n"," 'among',\n"," 'amongst',\n"," 'an',\n"," 'and',\n"," 'anoth',\n"," 'ani',\n"," 'anybodi',\n"," 'anyhow',\n"," 'anymor',\n"," 'anyon',\n"," 'anyth',\n"," 'anyway',\n"," 'anyway',\n"," 'anywher',\n"," 'are',\n"," 'aren',\n"," 'aren',\n"," 'arent',\n"," 'around',\n"," 'as',\n"," 'asid',\n"," 'at',\n"," 'away',\n"," 'be',\n"," 'becaus',\n"," 'been',\n"," 'befor',\n"," 'beforehand',\n"," 'behind',\n"," 'be',\n"," 'below',\n"," 'besid',\n"," 'besid',\n"," 'between',\n"," 'beyond',\n"," 'both',\n"," 'but',\n"," 'by',\n"," 'ca',\n"," 'can',\n"," 'can',\n"," \"can't\",\n"," 'cannot',\n"," 'caus',\n"," 'co',\n"," 'com',\n"," 'could',\n"," 'couldn',\n"," 'couldn',\n"," 'couldnt',\n"," 'day',\n"," 'day',\n"," 'despit',\n"," 'did',\n"," 'didn',\n"," 'didn',\n"," \"didn't\",\n"," 'do',\n"," 'doe',\n"," 'doesn',\n"," 'doesn',\n"," \"doesn't\",\n"," 'do',\n"," 'don',\n"," \"don't\",\n"," 'done',\n"," 'dont',\n"," 'down',\n"," 'downward',\n"," 'dure',\n"," 'each',\n"," 'ed',\n"," 'edu',\n"," 'eg',\n"," 'either',\n"," 'els',\n"," 'elsewher',\n"," 'enough',\n"," 'et',\n"," 'et-al',\n"," 'etc',\n"," 'even',\n"," 'ever',\n"," 'everi',\n"," 'everybodi',\n"," 'everyon',\n"," 'everyth',\n"," 'everywher',\n"," 'except',\n"," 'ff',\n"," 'for',\n"," 'from',\n"," 'further',\n"," 'furthermor',\n"," 'go',\n"," 'goe',\n"," 'go',\n"," 'gone',\n"," 'got',\n"," 'gotten',\n"," 'had',\n"," 'has',\n"," \"hasn't\",\n"," 'have',\n"," 'haven',\n"," 'haven',\n"," \"haven't\",\n"," 'have',\n"," 'he',\n"," 'hed',\n"," 'henc',\n"," 'her',\n"," 'here',\n"," 'hereaft',\n"," 'herebi',\n"," 'herein',\n"," 'here',\n"," 'hereupon',\n"," 'her',\n"," 'herself',\n"," 'hes',\n"," 'hi',\n"," 'him',\n"," 'himself',\n"," 'his',\n"," 'hither',\n"," 'how',\n"," 'howbeit',\n"," 'howev',\n"," 'i',\n"," \"i'll\",\n"," \"i'v\",\n"," 'id',\n"," 'ie',\n"," 'if',\n"," 'im',\n"," 'in',\n"," 'inc',\n"," 'instead',\n"," 'into',\n"," 'is',\n"," 'isn',\n"," 'isn',\n"," \"isn't\",\n"," 'it',\n"," \"it'll\",\n"," 'itd',\n"," 'it',\n"," 'itself',\n"," 'just',\n"," 'kg',\n"," 'km',\n"," 'larg',\n"," 'late',\n"," 'later',\n"," 'latter',\n"," 'latter',\n"," 'least',\n"," 'less',\n"," 'lest',\n"," 'let',\n"," 'let',\n"," 'like',\n"," 'like',\n"," 'liter',\n"," 'littl',\n"," 'll',\n"," 'lot',\n"," 'lot',\n"," 'ltd',\n"," 'made',\n"," 'main',\n"," 'mani',\n"," 'matter',\n"," 'may',\n"," 'mayb',\n"," 'me',\n"," 'mean',\n"," 'mean',\n"," 'meantim',\n"," 'meanwhil',\n"," 'mere',\n"," 'mg',\n"," 'might',\n"," 'ml',\n"," 'more',\n"," 'moreov',\n"," 'most',\n"," 'most',\n"," 'mr',\n"," 'mrs',\n"," 'much',\n"," 'must',\n"," 'my',\n"," 'myself',\n"," \"n't\",\n"," 'na',\n"," 'name',\n"," 'nay',\n"," 'nd',\n"," 'near',\n"," 'neither',\n"," 'never',\n"," 'nevertheless',\n"," 'no',\n"," 'nobodi',\n"," 'non',\n"," 'none',\n"," 'nonetheless',\n"," 'noon',\n"," 'nor',\n"," 'nos',\n"," 'not',\n"," 'noth',\n"," 'now',\n"," 'nowher',\n"," 'obvious',\n"," 'of',\n"," 'off',\n"," 'often',\n"," 'oh',\n"," 'ok',\n"," 'okay',\n"," 'on',\n"," 'onc',\n"," 'one',\n"," 'one',\n"," 'onli',\n"," 'onto',\n"," 'or',\n"," 'ord',\n"," 'other',\n"," 'other',\n"," 'otherwis',\n"," 'ought',\n"," 'our',\n"," 'our',\n"," 'ourselv',\n"," 'out',\n"," 'outsid',\n"," 'over',\n"," 'overal',\n"," 'particular',\n"," 'past',\n"," 'per',\n"," 'pleas',\n"," 'plus',\n"," 'pp',\n"," 'present',\n"," 'put',\n"," 'que',\n"," 'quit',\n"," 'qv',\n"," 'rather',\n"," 'rd',\n"," 're',\n"," 'realli',\n"," 'ref',\n"," 'ref',\n"," 'regard',\n"," 'regardless',\n"," 'regard',\n"," 'right',\n"," 's',\n"," 'said',\n"," 'same',\n"," 'saw',\n"," 'sec',\n"," 'second',\n"," 'second',\n"," 'see',\n"," 'seen',\n"," 'self',\n"," 'selv',\n"," 'serious',\n"," 'sever',\n"," 'shall',\n"," 'she',\n"," \"she'll\",\n"," 'shed',\n"," 'shes',\n"," 'should',\n"," \"shouldn't\",\n"," 'sinc',\n"," 'slight',\n"," 'so',\n"," 'some',\n"," 'somebodi',\n"," 'somehow',\n"," 'someon',\n"," 'somethan',\n"," 'someth',\n"," 'sometim',\n"," 'sometim',\n"," 'somewhat',\n"," 'somewher',\n"," 'still',\n"," 'stuff',\n"," 'sub',\n"," 'such',\n"," 'sup',\n"," 'super',\n"," 'sure',\n"," 't',\n"," 'th',\n"," 'than',\n"," 'thank',\n"," 'thank',\n"," 'thanx',\n"," 'that',\n"," \"that'll\",\n"," \"that'v\",\n"," 'that',\n"," 'the',\n"," 'their',\n"," 'their',\n"," 'them',\n"," 'themselv',\n"," 'then',\n"," 'thenc',\n"," 'there',\n"," \"there'l\",\n"," \"there'v\",\n"," 'thereaft',\n"," 'therebi',\n"," 'there',\n"," 'therefor',\n"," 'therein',\n"," 'thereof',\n"," 'there',\n"," 'thereto',\n"," 'thereupon',\n"," 'these',\n"," 'they',\n"," \"they'll\",\n"," \"they'v\",\n"," 'theyd',\n"," 'theyr',\n"," 'thing',\n"," 'thing',\n"," 'this',\n"," 'those',\n"," 'thou',\n"," 'though',\n"," 'though',\n"," 'thousand',\n"," 'through',\n"," 'throughout',\n"," 'thru',\n"," 'thus',\n"," 'til',\n"," 'till',\n"," 'to',\n"," 'too',\n"," 'total',\n"," 'toward',\n"," 'toward',\n"," 'ts',\n"," 'twice',\n"," 'two',\n"," 'un',\n"," 'under',\n"," 'unless',\n"," 'unlik',\n"," 'unlik',\n"," 'until',\n"," 'unto',\n"," 'up',\n"," 'upon',\n"," 'up',\n"," 'us',\n"," 'usual',\n"," 've',\n"," 'veri',\n"," 'veri',\n"," 'via',\n"," 'viz',\n"," 'vol',\n"," 'vol',\n"," 'vs',\n"," 'want',\n"," 'want',\n"," 'was',\n"," 'wasn',\n"," 'wasn',\n"," 'wasnt',\n"," 'way',\n"," 'we',\n"," \"we'll\",\n"," \"we'v\",\n"," 'wed',\n"," 'well',\n"," 'went',\n"," 'were',\n"," 'werent',\n"," 'what',\n"," \"what'll\",\n"," 'whatev',\n"," 'what',\n"," 'when',\n"," 'whenc',\n"," 'whenev',\n"," 'where',\n"," 'whereaft',\n"," 'wherea',\n"," 'wherebi',\n"," 'wherein',\n"," 'where',\n"," 'whereupon',\n"," 'wherev',\n"," 'whether',\n"," 'which',\n"," 'while',\n"," 'whim',\n"," 'whither',\n"," 'who',\n"," \"who'll\",\n"," 'whod',\n"," 'whoever',\n"," 'whom',\n"," 'whomev',\n"," 'whos',\n"," 'whose',\n"," 'whi',\n"," 'will',\n"," 'will',\n"," 'with',\n"," 'within',\n"," 'without',\n"," 'wont',\n"," 'wors',\n"," 'worst',\n"," 'would',\n"," 'wouldn',\n"," 'wouldn',\n"," 'wouldnt',\n"," 'wow',\n"," 'www',\n"," 'yes',\n"," 'yet',\n"," 'you',\n"," \"you'll\",\n"," \"you'v\",\n"," 'youd',\n"," 'your',\n"," 'your',\n"," 'your',\n"," 'yourself',\n"," 'yourselv']"]},"metadata":{},"execution_count":23},{"output_type":"stream","name":"stdout","text":["time: 16.5 ms (started: 2021-09-18 04:18:32 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"pm09PD0I9jTh"},"source":["### Load the BBC dataset into a Pandas dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"LzEuUegn7zUx","executionInfo":{"status":"ok","timestamp":1631935500748,"user_tz":300,"elapsed":937,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"1aa5de37-7b9a-471c-ded2-fd4cdd8bee35"},"source":["bbc_dataset = \"datasets/bbc-text.csv\"\n","df = pd.read_csv(bbc_dataset)\n","df.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tech</td>\n","      <td>tv future in the hands of viewers with home th...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>business</td>\n","      <td>worldcom boss  left books alone  former worldc...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sport</td>\n","      <td>tigers wary of farrell  gamble  leicester say ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sport</td>\n","      <td>yeading face newcastle in fa cup premiership s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>entertainment</td>\n","      <td>ocean s twelve raids box office ocean s twelve...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        category                                               text\n","0           tech  tv future in the hands of viewers with home th...\n","1       business  worldcom boss  left books alone  former worldc...\n","2          sport  tigers wary of farrell  gamble  leicester say ...\n","3          sport  yeading face newcastle in fa cup premiership s...\n","4  entertainment  ocean s twelve raids box office ocean s twelve..."]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hyvx4Q328nTE","executionInfo":{"status":"ok","timestamp":1631935702799,"user_tz":300,"elapsed":109,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"764fd179-3185-4dd8-cc1d-2fc5cf692a54"},"source":["df.info()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2225 entries, 0 to 2224\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   category  2225 non-null   object\n"," 1   text      2225 non-null   object\n","dtypes: object(2)\n","memory usage: 34.9+ KB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veGZHksq8tED","executionInfo":{"status":"ok","timestamp":1631935799243,"user_tz":300,"elapsed":121,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"17206309-7cb0-4ce3-fa8f-6cfbf6063d47"},"source":["df.category.value_counts()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sport            511\n","business         510\n","politics         417\n","tech             401\n","entertainment    386\n","Name: category, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"twZPRoca63So","executionInfo":{"status":"ok","timestamp":1631935508326,"user_tz":300,"elapsed":249,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"0b08bd74-4e39-4a77-c05f-71c329c2a810"},"source":["def clean_data(df):\n","    df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n","    df['text'] = df['text'].apply(lambda x: re.sub(r'\\d', '', x))\n","    return df\n","\n","df = clean_data(df)\n","documents = df['text']\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tech</td>\n","      <td>tv future in the hands of viewers with home th...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>business</td>\n","      <td>worldcom boss  left books alone  former worldc...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sport</td>\n","      <td>tigers wary of farrell  gamble  leicester say ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sport</td>\n","      <td>yeading face newcastle in fa cup premiership s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>entertainment</td>\n","      <td>ocean s twelve raids box office ocean s twelve...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        category                                               text\n","0           tech  tv future in the hands of viewers with home th...\n","1       business  worldcom boss  left books alone  former worldc...\n","2          sport  tigers wary of farrell  gamble  leicester say ...\n","3          sport  yeading face newcastle in fa cup premiership s...\n","4  entertainment  ocean s twelve raids box office ocean s twelve..."]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7pGUoEm9Z8w","executionInfo":{"status":"ok","timestamp":1631937186098,"user_tz":300,"elapsed":609,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"06c02f48-46e5-43e9-cc77-deab37441363"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","import string\n","import re\n","import nltk\n","nltk.download('punkt')\n","\n","stemmer = SnowballStemmer('english')\n","\n","def tokenize_and_stem(sentence):\n","    tokens = nltk.word_tokenize(sentence)\n","    filtered_tokens = [t for t in tokens if t not in stopwords and t not in string.punctuation and re.search('[a-zA-Z]', t)]\n","    stems = [stemmer.stem(t) for t in filtered_tokens]\n","    return stems\n","\n","def create_tf_idf_vectorizer(documents):\n","  tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords,\n","                                       tokenizer=tokenize_and_stem, \n","                                       max_df=0.95, \n","                                       max_features=20000,\n","                                       use_idf=True)\n","  data = tfidf_vectorizer.fit_transform(documents)\n","  return (tfidf_vectorizer, data)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmMcgIGrBYng","executionInfo":{"status":"ok","timestamp":1631937212188,"user_tz":300,"elapsed":20054,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"cda87280-eca3-4dc1-ac06-499a623b4076"},"source":["(tfidf_vectorizer, data) = create_tf_idf_vectorizer(documents)\n","data"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2225x18650 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 284079 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"ma9SJofWCsyL","executionInfo":{"status":"ok","timestamp":1631937380129,"user_tz":300,"elapsed":11457,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}}},"source":["from sklearn.decomposition import LatentDirichletAllocation as LDA\n","\n","def create_and_fit_lda(data, num_topics):\n","    lda = LDA(n_components=num_topics, n_jobs=-1)\n","    lda.fit(data)\n","    return lda\n","\n","number_topics = 5\n","lda = create_and_fit_lda(data, number_topics)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxXZHJgZDlND","executionInfo":{"status":"ok","timestamp":1631937905470,"user_tz":300,"elapsed":127,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"6dfd9ca9-2368-4f96-98cb-d8d8158fc5dd"},"source":["def get_most_common_words_for_topics(model, vectorizer, n_top_words):\n","    words = vectorizer.get_feature_names()\n","    word_dict = {}\n","    for topic_index, topic in enumerate(model.components_):\n","        this_topic_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n","        word_dict[topic_index] = this_topic_words\n","    return word_dict\n","\n","def print_topic_words(word_dict):\n","    for key in word_dict.keys():\n","        print(f\"Topic {key}\")\n","        print(\"\\t\", word_dict[key])\n","\n","topic_words = get_most_common_words_for_topics(lda, tfidf_vectorizer,20)\n","print_topic_words(topic_words)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic 0\n","\t ['film', 'm', 'year', 'best', 'award', 'game', 'star', 'play', 'win', 'show', 'last', 'time', 'sale', 'first', 'music', 'won', 'world', 'top', 'new', 'rate']\n","Topic 1\n","\t ['peopl', 'govern', 'elect', 'use', 'labour', 'say', 'parti', 'bn', 'firm', 'compani', 'year', 'new', 'blair', 'servic', 'minist', 'mobil', 'tax', 'plan', 'tori', 'phone']\n","Topic 2\n","\t ['england', 'wale', 'o', 'ireland', 'match', 'rugbi', 'win', 'play', 'seed', 'injuri', 'game', 'robinson', 'franc', 'coach', 'open', 'six', 'player', 'final', 'william', 'half']\n","Topic 3\n","\t ['printer', 'cartridg', 'ssl', 'nestl', 'wpp', 'metlif', 'elgindi', 'curbishley', 'pernod', 'carniv', 'inkjet', 'sakhnin', 'domecq', 'bnei', 'murambadoro', 'electrolux', 'jonatan', 'coltran', 'aurora', 'condom']\n","Topic 4\n","\t ['commodor', 'qanta', 'mido', 'melcher', 'newri', 'scoggin', 'mukesh', 'tulu', 'yili', 'ambani', 'ead', 'winn', 'dixi', 'camus', 'anil', 'forgeard', 'meldrum', 'hillbilli', 'turkmen', 'turkmenistan']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BCMoXQNHy4N","executionInfo":{"status":"ok","timestamp":1631938625525,"user_tz":300,"elapsed":1864,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"c1309dbe-0ead-450a-9ab2-92a868a9548c"},"source":["import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","docs = [\"We've been running all day.\", \"Let's be better.\"]\n","\n","for doc in nlp.pipe(docs, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n","    print([tok.lemma_ for tok in doc])"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['-PRON-', 'have', 'be', 'run', 'all', 'day', '.']\n","['let', '-PRON-', 'be', 'well', '.']\n","time: 1.76 s (started: 2021-09-18 04:17:03 +00:00)\n"]}]},{"cell_type":"code","metadata":{"id":"-cY_EiVHLoFK","executionInfo":{"status":"ok","timestamp":1631939630132,"user_tz":300,"elapsed":127,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"54e30103-b169-48ca-ea9c-adcdfeab9503","colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["df['text'][0]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'tv future in the hands of viewers with home theatre systems  plasma high definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time   that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite pastimes  with the us leading the trend  programmes and other content will be delivered to viewers via home networks  through cable  satellite  telecoms companies  and broadband service providers to front rooms and portable devices   one of the most talked about technologies of ces has been digital and personal video recorders  dvr and pvr   these set top boxes  like the us s tivo and the uk s sky  system  allow people to record  store  play  pause and forward wind tv programmes when they want   essentially  the technology allows for much more personalised tv  they are also being built in to high definition tv sets  which are big business in japan and the us  but slower to take off in europe because of the lack of high definition programming  not only can people forward wind through adverts  they can also forget about abiding by network and channel schedules  putting together their own a la carte entertainment  but some us networks and cable and satellite companies are worried about what it means for them in terms of advertising revenues as well as  brand identity  and viewer loyalty to channels  although the us leads in this technology at the moment  it is also a concern that is being raised in europe  particularly with the growing uptake of services like sky    what happens here today  we will see in nine months to a years  time in the uk   adam hume  the bbc broadcast s futurologist told the bbc news website  for the likes of the bbc  there are no issues of lost advertising revenue yet  it is a more pressing issue at the moment for commercial uk broadcasters  but brand loyalty is important for everyone   we will be talking more about content brands rather than network brands   said tim hanlon  from brand communications firm starcom mediavest   the reality is that with broadband connections  anybody can be the producer of content   he added   the challenge now is that it is hard to promote a programme with so much choice    what this means  said stacey jolna  senior vice president of tv guide tv group  is that the way people find the content they want to watch has to be simplified for tv viewers  it means that networks  in us terms  or channels could take a leaf out of google s book and be the search engine of the future  instead of the scheduler to help people find what they want to watch  this kind of channel model might work for the younger ipod generation which is used to taking control of their gadgets and what they play on them  but it might not suit everyone  the panel recognised  older generations are more comfortable with familiar schedules and channel brands because they know what they are getting  they perhaps do not want so much of the choice put into their hands  mr hanlon suggested   on the other end  you have the kids just out of diapers who are pushing buttons already   everything is possible and available to them   said mr hanlon   ultimately  the consumer will tell the market they want    of the   new gadgets and technologies being showcased at ces  many of them are about enhancing the tv watching experience  high definition tv sets are everywhere and many new models of lcd  liquid crystal display  tvs have been launched with dvr capability built into them  instead of being external boxes  one such example launched at the show is humax s  inch lcd tv with an  hour tivo dvr and dvd recorder  one of the us s biggest satellite tv companies  directtv  has even launched its own branded dvr at the show with  hours of recording capability  instant replay  and a search function  the set can pause and rewind tv for up to  hours  and microsoft chief bill gates announced in his pre show keynote speech a partnership with tivo  called tivotogo  which means people can play recorded programmes on windows pcs and mobile devices  all these reflect the increasing trend of freeing up multimedia so that people can watch what they want  when they want '"]},"metadata":{},"execution_count":24},{"output_type":"stream","name":"stdout","text":["time: 5.54 ms (started: 2021-09-18 04:33:49 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"jlAagv7dOngB"},"source":["<a name='3'></a>\n","## 3 - Preprocess the dataset ##\n","\n","In general, it's a good practice to develop models that take raw data as input, as opposed to models that take already-preprocessed data. The reason being that, if the model expects preprocessed data, any time we export the model to use it elsewhere (in a web browser, in a mobile app), we'll need to reimplement the exact same preprocessing pipeline. This gets very tricky. So we should do the least possible amount of preprocessing before hitting the model.\n","\n","Here, we'll do image resizing in the data pipeline (because a deep neural network can only process contiguous batches of data), and we'll do the input value scaling as part of the model, when we create it."]},{"cell_type":"markdown","metadata":{"id":"2OlNdeoHOr_h"},"source":["### Resize the images to 150x150\n"]},{"cell_type":"code","metadata":{"id":"hOpHOYfGOZej"},"source":["size = (150, 150)\n","train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n","validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n","test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Og6pgDJQlzA"},"source":["Besides, let's batch the data and use caching & prefetching to optimize loading speed."]},{"cell_type":"code","metadata":{"id":"XHjUu6oCQonF"},"source":["batch_size = 32\n","train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n","validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n","test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Bnd7DHJRHjh"},"source":["<a name='4'></a>\n","## 4 - Build the model ## \n"]},{"cell_type":"markdown","metadata":{"id":"ciIExmeURI1p"},"source":["<a name='4-1'></a>\n","### 4.1 - Define the model structure\n","\n","**Note that**:\n","- We add a `Rescaling` layer to scale input values (initially in the [0, 255] range) to the [-1, 1] range.\n","- We add a `Image Augumentation` layers to help expose the model to different aspects of the training data while slowing down overfitting.\n","- We add a `Dropout` layer before the classification layer, for regularization.\n","- We make sure to pass `training=False` when calling the base model, so that it runs in inference mode, so that batchnorm statistics don't get updated even after we unfreeze the base model for fine-tuning."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N7P_aDfQxel","executionInfo":{"status":"ok","timestamp":1631807817908,"user_tz":300,"elapsed":2229,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"0a872c76-b503-47a4-fc48-8a54f7bfad21"},"source":["from tensorflow.keras import layers\n","\n","# Create the base_model\n","base_model = keras.applications.Xception(\n","    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n","    input_shape=(150, 150, 3),\n","    include_top=False,  # Do not include the ImageNet classifier at the top.\n","    )  \n","\n","# Freeze the base_model\n","base_model.trainable = False\n","\n","# Create new model on top\n","inputs = keras.Input(shape=(150, 150, 3))\n","\n","# Apply random data augmentation\n","data_augmentation = keras.Sequential(\n","    [layers.RandomFlip(\"horizontal\"), \n","     layers.RandomRotation(0.1),]\n","     )\n","x = data_augmentation(inputs)  \n","\n","# Pre-trained Xception weights requires that input be scaled\n","# from (0, 255) to a range of (-1., +1.), the rescaling layer\n","# outputs: `(inputs * scale) + offset`\n","scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n","x = scale_layer(x)\n","\n","# The base model contains batchnorm layers. We want to keep them in inference mode\n","# when we unfreeze the base model for fine-tuning, so we make sure that the\n","# base_model is running in inference mode here.\n","x = base_model(x, training=False)\n","x = keras.layers.GlobalAveragePooling2D()(x)  # Convert features to vectors\n","x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n","outputs = keras.layers.Dense(1)(x)  # Binary classification)\n","model = keras.Model(inputs, outputs)\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n","_________________________________________________________________\n","sequential (Sequential)      (None, 150, 150, 3)       0         \n","_________________________________________________________________\n","rescaling (Rescaling)        (None, 150, 150, 3)       0         \n","_________________________________________________________________\n","xception (Functional)        (None, 5, 5, 2048)        20861480  \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 2048)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 2049      \n","=================================================================\n","Total params: 20,863,529\n","Trainable params: 2,049\n","Non-trainable params: 20,861,480\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"3DUu-5JRT46J"},"source":["<a name='4-2'></a>\n","### 4.2 - Train the top layer\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzrYQbcUTsGM","executionInfo":{"status":"ok","timestamp":1631809078896,"user_tz":300,"elapsed":1260994,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"bd2d7374-3e5f-4865-b4c0-6b2ab6efc1a6"},"source":["model.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.BinaryAccuracy()],\n","    )\n","\n","epochs = 20\n","model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","291/291 [==============================] - 86s 192ms/step - loss: 0.1664 - binary_accuracy: 0.9257 - val_loss: 0.0815 - val_binary_accuracy: 0.9721\n","Epoch 2/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.1210 - binary_accuracy: 0.9492 - val_loss: 0.0755 - val_binary_accuracy: 0.9733\n","Epoch 3/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.1103 - binary_accuracy: 0.9548 - val_loss: 0.0746 - val_binary_accuracy: 0.9721\n","Epoch 4/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.1085 - binary_accuracy: 0.9557 - val_loss: 0.0733 - val_binary_accuracy: 0.9733\n","Epoch 5/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.1036 - binary_accuracy: 0.9570 - val_loss: 0.0708 - val_binary_accuracy: 0.9738\n","Epoch 6/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.1016 - binary_accuracy: 0.9564 - val_loss: 0.0715 - val_binary_accuracy: 0.9716\n","Epoch 7/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0941 - binary_accuracy: 0.9636 - val_loss: 0.0713 - val_binary_accuracy: 0.9725\n","Epoch 8/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0970 - binary_accuracy: 0.9601 - val_loss: 0.0769 - val_binary_accuracy: 0.9695\n","Epoch 9/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0992 - binary_accuracy: 0.9593 - val_loss: 0.0831 - val_binary_accuracy: 0.9686\n","Epoch 10/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0964 - binary_accuracy: 0.9612 - val_loss: 0.0695 - val_binary_accuracy: 0.9729\n","Epoch 11/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0917 - binary_accuracy: 0.9626 - val_loss: 0.0684 - val_binary_accuracy: 0.9725\n","Epoch 12/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0906 - binary_accuracy: 0.9627 - val_loss: 0.0689 - val_binary_accuracy: 0.9716\n","Epoch 13/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0945 - binary_accuracy: 0.9609 - val_loss: 0.0740 - val_binary_accuracy: 0.9699\n","Epoch 14/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.1014 - binary_accuracy: 0.9613 - val_loss: 0.0712 - val_binary_accuracy: 0.9712\n","Epoch 15/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0919 - binary_accuracy: 0.9636 - val_loss: 0.0719 - val_binary_accuracy: 0.9712\n","Epoch 16/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0895 - binary_accuracy: 0.9635 - val_loss: 0.0765 - val_binary_accuracy: 0.9699\n","Epoch 17/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0914 - binary_accuracy: 0.9643 - val_loss: 0.0699 - val_binary_accuracy: 0.9733\n","Epoch 18/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0931 - binary_accuracy: 0.9621 - val_loss: 0.0698 - val_binary_accuracy: 0.9725\n","Epoch 19/20\n","291/291 [==============================] - 53s 181ms/step - loss: 0.0874 - binary_accuracy: 0.9649 - val_loss: 0.0737 - val_binary_accuracy: 0.9721\n","Epoch 20/20\n","291/291 [==============================] - 52s 180ms/step - loss: 0.0874 - binary_accuracy: 0.9650 - val_loss: 0.0788 - val_binary_accuracy: 0.9690\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1365aee650>"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Lyzadlk_WBCh"},"source":["<a name='4-3'></a>\n","### 4.3 - Fine-tuning\n","\n","Finally, let's unfreeze the base model and train the entire model end-to-end with a low learning rate.\n","\n","Importantly, although the base model becomes trainable, it is still running in inference mode since we passed `training=False` when calling it when we built the model. This means that the batch normalization layers inside won't update their batch statistics. If they did, they would wreck havoc on the representations learned by the model so far."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ptscewCWv4T","executionInfo":{"status":"ok","timestamp":1631811123117,"user_tz":300,"elapsed":2014262,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"df6c901f-de6e-4c55-b1ac-dd850f45fd5c"},"source":["base_model.trainable = True\n","print(model.summary())\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n","    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.BinaryAccuracy()],\n","    )\n","\n","epochs = 10\n","model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n","_________________________________________________________________\n","sequential (Sequential)      (None, 150, 150, 3)       0         \n","_________________________________________________________________\n","rescaling (Rescaling)        (None, 150, 150, 3)       0         \n","_________________________________________________________________\n","xception (Functional)        (None, 5, 5, 2048)        20861480  \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 2048)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 2049      \n","=================================================================\n","Total params: 20,863,529\n","Trainable params: 20,809,001\n","Non-trainable params: 54,528\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","291/291 [==============================] - 202s 666ms/step - loss: 0.0787 - binary_accuracy: 0.9673 - val_loss: 0.0571 - val_binary_accuracy: 0.9751\n","Epoch 2/10\n","291/291 [==============================] - 191s 656ms/step - loss: 0.0554 - binary_accuracy: 0.9778 - val_loss: 0.0569 - val_binary_accuracy: 0.9768\n","Epoch 3/10\n","291/291 [==============================] - 191s 657ms/step - loss: 0.0427 - binary_accuracy: 0.9850 - val_loss: 0.0561 - val_binary_accuracy: 0.9781\n","Epoch 4/10\n","291/291 [==============================] - 191s 657ms/step - loss: 0.0330 - binary_accuracy: 0.9870 - val_loss: 0.0483 - val_binary_accuracy: 0.9798\n","Epoch 5/10\n","291/291 [==============================] - 191s 657ms/step - loss: 0.0292 - binary_accuracy: 0.9887 - val_loss: 0.0462 - val_binary_accuracy: 0.9815\n","Epoch 6/10\n","291/291 [==============================] - 191s 658ms/step - loss: 0.0219 - binary_accuracy: 0.9914 - val_loss: 0.0459 - val_binary_accuracy: 0.9802\n","Epoch 7/10\n","291/291 [==============================] - 191s 655ms/step - loss: 0.0182 - binary_accuracy: 0.9934 - val_loss: 0.0389 - val_binary_accuracy: 0.9854\n","Epoch 8/10\n","291/291 [==============================] - 191s 655ms/step - loss: 0.0196 - binary_accuracy: 0.9930 - val_loss: 0.0469 - val_binary_accuracy: 0.9802\n","Epoch 9/10\n","291/291 [==============================] - 191s 656ms/step - loss: 0.0162 - binary_accuracy: 0.9944 - val_loss: 0.0524 - val_binary_accuracy: 0.9828\n","Epoch 10/10\n","291/291 [==============================] - 192s 659ms/step - loss: 0.0138 - binary_accuracy: 0.9951 - val_loss: 0.0524 - val_binary_accuracy: 0.9832\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1363f933d0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"M8wGDpRUXfBl"},"source":["After 10 epochs, fine-tuning gains us a nice improvement here."]},{"cell_type":"markdown","metadata":{"id":"AWJrV5IxdXNU"},"source":["<a name='5'></a>\n","### 5 - Save the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS0LyefUdfyJ","executionInfo":{"status":"ok","timestamp":1631812163584,"user_tz":300,"elapsed":32429,"user":{"displayName":"Daniel Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01562824883738723040"}},"outputId":"622545b7-6db1-48de-a585-c66f48b6c0f8"},"source":["model.save('finetuned_model')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: finetuned_model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: finetuned_model/assets\n","/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]}]}]}